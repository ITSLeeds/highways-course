---
output: github_document
---

<!-- Note: edit the .Rmd file not the .md file -->

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
library(tidyverse)
```

# Exercises day 2

## 1 Recap and point data

1. Start off by attaching the **tidyverse** with the `library()` function.
1. Create (or recreate) an object called `ac_wy` with the command `read_csv()` (you may need to first download the file from https://github.com/ITSLeeds/highways-course/releases )
    ```{r}
    ac_wy = read_csv("ac_wy.csv")
    # class(ac_wy)
    ```
1. What is the class of the `ac_wy`?
1. Create a plot of dataset using **ggplot2**, resulting in a plot that looks a little like this (hint: set transparency with `alpha` in `geom_point()`, fix the coordinates with `+ coord_equal()`):
    ```{r}
    ggplot(ac_wy, aes(x = ac_wy$Location_Easting_OSGR, Location_Northing_OSGR, colour = Accident_Severity)) + 
        geom_point(alpha = 0.5) +
        coord_equal()
        # ggplot(ac_wy, aes(x = Location_Easting_OSGR, Location_Northing_OSGR, colour = Accident_Severity, size = Number_of_Casualties)) + 
        # geom_point(alpha = 0.5) +
        # theme_void() +
        #     coord_equal()
    ```
1. Building on the previous plot, make the size of each dot proportional to the number of people involved (`Number_of_Casualties`).
1. Filter the dataset so that it contains only rows with `Accident_Severity` values of `Killed` or `Serious` (hint: `!= "Slight"` may help!).
    ```{r}
    ac_wy = ac_wy %>% 
        filter(Accident_Severity != "Slight")
    ```
1. Further reduce the dataset size by selecting only the following columns for further analysis: `Accident_Index, Location_Easting_OSGR, Location_Northing_OSGR, Accident_Severity, Date, Speed_limit`.
    ```{r}
    ac_wy = ac_wy %>% 
        select(Accident_Index, Location_Easting_OSGR, Location_Northing_OSGR, Accident_Severity, Date, Speed_limit)
    ```
1. Create a new plot showing the distribution of speed limits.
    ```{r}
    ggplot(ac_wy, aes(x = ac_wy$Location_Easting_OSGR, Location_Northing_OSGR, colour = Speed_limit)) + 
        geom_point(alpha = 0.5) +
        coord_equal()
    ```
1. Load the **sf** library.
1. reate an object called `ac_wy_sf`, a spatial version of the `ac_wy` dataset read-in previously (hint: use the function `st_as_sf()` and coordinate variables Location_Easting_OSGR/Location_Northing_OSGR --- set the CRS with `crs = 27700`)
    ```{r}
    library(sf)
    ac_wy_sf = st_as_sf(ac_wy,
                        coords = c("Location_Easting_OSGR", "Location_Northing_OSGR"),
                        crs = 27700)
    ```
3. Plot the result with **tmap**, showing accident severity (hint: the code below plots the result for the speed limit).
    ```{r, eval=FALSE, echo=TRUE}
    library(tmap)
    tm_shape(ac_wy_sf) +
        tm_dots("Speed_limit")
    ```
1. Set the mode of **tmap** to viewing with `tmap_mode("view")` and run the previous command again to create an interactive map.
1. Use this to visually identify a junction with many crashes.
1. Read-in a dataset representing Leeds with the following command (note: you need to have downloaded the file from https://github.com/ITSLeeds/highways-course/releases ):
    ```{r, echo=TRUE}
    leeds = readRDS("leeds.Rds")
    ```
1. Find the CRS of `leeds` with `st_crs()`
1. Transform the CRS to OSGB with the command `st_transform()` (hint: OSGB has the EPSG code 27700).
    ```{r}
    library(sf)
    leeds = st_transform(leeds, 27700)
    ```
5. Find out how many fatal and serious crashes happened in each of the MSOA areas in Leeds
    ```{r, echo=FALSE}
    msoa_ksi = aggregate(ac_wy_sf[1], leeds, FUN = length)
    plot(msoa_ksi)
    ```
    
## Advanced

- Advanced 1: Find out which MSOA zone had the highest average number of people in crashes
- Advanced 2: Look-up packages for clustering (hint: look at https://geocompr.github.io/geocompkg/articles/ )
- Advanced 3 (difficult): Aggregate point to regular grid cells